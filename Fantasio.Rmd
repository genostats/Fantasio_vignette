---
title: "Fantasio"
author: "Isuru HAUPE & Marie MICHEL"
version: 0.1
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteDepends{Fantasio}
  %\VignettePackage{Fantasio}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
## Introduction

Fantasio is composed of several functions. Its goals are for:

* Population genetic studies (estimating and detecting inbreeding on individuals without known genealogy, estimating the population proportion of mating types and the individual probability to be offspring of different mating types)
* Rare disease studies (performing homozygosity mapping with heterogeneity)
* Multifactorial disease studies (HBD-GWAS strategy).

Fantasio  implements the creation of several random sparse submaps on genome-wide data (to remove linkage disequilibrium). It also provides graphical outputs to facilitate interpretations of homozygosity mapping results and plots.

In this vignette, we illustrate how to use the package, using the data set HGDP-CEPH, a ship which contains 1043 individuals and 660918 markers. In order to access the data, you will need to download the HGDP.CEPH package (see below how) and load it.

Not  all options of the functions are described here, but rather their basic usage.  The reader is advised to look at the manual page of the function for details.

### Principal concepts

Fantasio is a maximum likelihood method that uses a hidden Markov chain to model the dependencies along the genome between the (observed) marker genotypes of an individual, and its (unobserved) homozygous by descent (HBD) status. The emission probabilities of this hidden Markov model (HMM) depend on the allele frequencies. The transition probabilities depend on the genetic distance between two adjacent markers. This model allows estimating the inbreeding coefficient $f$ of an individual, and a parameter $a$, where $af$ is the instantaneous rate of change per unit map length (here cM) from no HBD to HBD. Both HBD and non-HBD segment lengths are assumed to be distributed exponentially with mean lengths $\frac{1}{a(1-f)}$ and $\frac{1}{af}$, respectively.

Fantasio requires the markers to be in minimal linkage disequilibrium (LD). Otherwise biased estimations of $f$ are produced. A strategy consisting of generating multiple random sparse genome maps (submaps) has been proposed to avoid this bias (Leutenegger et al. 2011). When several submaps are considered, $f$ is estimated as the median value of the estimates obtained on the different maps after removing submaps with $a > 1$ (having an average HBD segment length of 1 cM is unlikely to be detected with a SNP density of 1 per 0.5 cM). This strategy has the advantage of not requiring any LD computation on the sample and of minimizing loss of information, as compared with a strategy that based on a single map of markers in minimal LD.

Fantasio compute the likelihood of a mating type. These likelihoods can be used for:

* Inferring an individual as inbred by comparing the maximized likelihood with the one to be outbred with a likelihood ratio test
* Estimating the population proportion of mating types
* Estimating the individual probability to be into different mating types

When multiple submaps are used, the median p-values/probabilities are considered. See
Leutenegger et al. 2011 for more details on the calculations.

Homozygosity mapping (Lander and Botstein 1987) consists in focusing on inbred affected individuals
and searching for a region of the genome of shared homozygosity. Original homozygosity mapping requires that the genealogy of patients be known so that inbred patients can be identified and their respective $f$ estimated. Leutenegger et al. (Leutenegger et al. 2006) proposed using the $f$ estimated on genome-wide genetic data to compute a FLOD score, similar to Mortons LOD score (Morton 1955). This FLOD score can be computed on isolated cases or on nuclear families.

Genin et al. (Genin et al. 2012) adapted the FLOD formula for multiple submaps. FLOD(i)(m,s) is computed for each individual $i$, each marker $m$ on each submap $s$, using the equation:

$$FLOD^{(i)}m,s = log_{10}\frac{P\left(Y_{m,s}^{(i)} | H_{1}\right)}{P\left(Y_{m,s}^{(i)} | H_{0}\right)} = log_{10}\frac{P\left(X_{m,s}^{(i)}=1 | Y_{m,s}^{(i)}\right) + q.P\left(X_{m,s}^{(i)}=1 | Y_{m,s}^{(i)}\right)}{\hat{f}_s^{(i)} + q.\left(1-\hat{f}_s^{(i)}\right)}$$ 

With the following parameters : 

* $Y_{m,s}^{(i)}$ the observed genotype of individual _i_ at marker _m_ on submap _s_
* $H_{1}$ the hypothesis where $Y_{m,s}^{(i)}$ is linked to the disease, and $H_{0}$ the one where it is not
* $X_{m,s}^{(i)}$ the HBD status of individual _i_ at marker _m_ on submap _s_ that is estimated together with
the inbreeding coefficient using the HMM of Fantasio
* $\hat{f}_s^{(i)}$ the estimated inbreeding coefficient of individual _i_ on submap _s_
This heterogeneity score is then maximized over α to evaluate the evidence of linkage at marker m
* _q_ the assumed frequency of the mutation involved in the disease for this individual.

Results are then averaged over the different submaps to obtain a single $FLOD^{(i)}(m)$ at each marker _m_.

Genin et al. (Genin et al. 2012) proposed to detect fully penetrant rare recessive variants by performing homozygosity mapping on inbred cases from Genome-Wide Association Study (GWAS) data. Linkage evidence is then evaluated over the entire set I of inbred cases by computing a FLOD score, HFLOD(m,α), at each marker m, with a heterogeneity parameter α, that takes into account the possibility that only a fraction of the inbred affected individuals carry diseases causing mutations:

$$HFLOD(m,\alpha)=\sum log_{10} \left[\alpha.\frac{P\left(Y_{m,s}^{(i)} | H_{1}\right)}{P\left(Y_{m,s}^{(i)} | H_{0}\right)}+ (1 - \alpha)\right ]= \sum log_{10} \left[\alpha . exp \left(FLOD^{(i)}(m)*log(10)\right)+(1-\alpha)\right] $$ 
This heterogeneity score is then maximized over $\alpha$ to evaluate the evidence of linkage at marker _m_ where $\alpha$ is the estimate of the proportion of cases linked to this locus:
$$HFLOD(m)=max_{\alpha}(HFLOD(m,\alpha))$$ 

##1. Getting started

The first thing you should know is that the package Fantasio depends on package gaston, please make sure to have it installed. 

Please refer to the vignette of this package for more information.

Since we explained the concept behind the package let's make an usage example of it. For this we will use the data furnish by the package HGDP. 

###1.1 Installation

First and faremost install the package with the following command : 

```{r eval=FALSE}
install.packages("Fantasio")
```

After doing that we will need to run the following commands :

```{r}
require(Fantasio) 
```

```{r eval=FALSE}
install.packages("HGDP.CEPH", repos="https://genostats.github.io/R/") #in order to download the dataset from which will work on.
```

```{r}
require(HGDP.CEPH)
```

###1.2 Input data file
From now on, we can use the package. Let us first create our bed.matrix object using the data file we load with the package HGDP.CEPH.

```{r}
filepath <-system.file("extdata", "hgdp_ceph.bed", package="HGDP.CEPH")
```

###1.3 Creation of the bed matrix
First create your bed.matrix object with this command :

```{r}
x <- read.bed.matrix(filepath)
```

Then return an updated 'bed.matrix' with new variables for several basic statistics : 

```{r}
x <- set.stats(x)
```

Here we only want to work on the Bedouin's data, so we selected this population with the following command :

```{r}
x.me <- select.inds(x, population == "Bedouin")
```

Please refer to the manual function of read.bed.matrix, set.stats and select.inds if needed (package gaston).

As Fantasio computes only for people affected by a disease, we change the STATUS of every individuals from 0 (=unknown) to 2 (=affected) : 
```{r}
x.me <- set.status(x.me, 2)
```

You can insure that your bed.matrix object is created and have the data needed with :

```{r}
str(x.me)
```

This object contains two slots : 

* ped  : which gives you informations about all the individuals in the chipset 
* snps : which gives you informations about the snps itself

More information in the vignette of the gaston package.

##2. Wrapper

We created a wrapper to make it easy to use the package.

The function calls two differents functions : `createSegmentsListBySnps`  and `createSegmentsListBySnps`. The first function `createSegmentsListBySnps` is used to create a list of segments though the genome. The second function `makeAllSubmapsBySnps` or `makeAllSubsmapsbyHotspots` is used to create submaps.

The segments arguments accept only two options : Hotspots or Distance.

###2.1 By Hotspots
```{r eval=FALSE}
submaps2 <- Fantasio(bedmatrix=x.me, segments="Hotspot", n=5, verbose=FALSE) #for clarity sake we put verbose to FALSE
```

###2.2 By Hotspots by Segments

```{r eval=FALSE}
submaps3 <- Fantasio(bedmatrix=x, segments="Hotspots", segment.options=l, n=100, n.cores=20, recap.by.segments=TRUE, n.consecutive.marker=1)
```

###2.3 By Distance

```{r eval=FALSE}
submaps4 <- Fantasio(bedmatrix=x.me, segments="Distance", n=5, verbose=FALSE) #for clarity sake we put verbose to FALSE
```

###2.4 How to use the segment.option argument

In order to use the `segment.option` argument you need to pass a list of arguments, each variable names in the list are an argument in the function. The function that will be called is either `createsSegmentsListBySnps` if `segments` argument is equal to "Distance" or `createSegmentsListByHotspots`if `segments` argument is equal to "Hotspots"  and the arguments list will be pass to it.

```{r eval=FALSE}
l <- list(number_of_marker=50) #default is 0
submaps5 <- Fantasio(bedmatrix=x, segments="Hotspots", segment.options=l, n=5, recap.by.segments=TRUE)
```


##3. Step by step usage of the package Fantasio

We implemented in the package Fantasio two differents methods in order to create the submaps : 

* By "Hotspots" : 
    *With this method we use hotspots files to segment our data, each segment contains several markers.
     Once this step is done we then loop over the segments and pick one marker randomly. By   
     doing this process we obtain a submap (a list of marker).
  
* By "Distance" : 
    *With this method we use the gaps between markers to segment our data, each segment contains several     
     markers. We then create mini-segments for each marker (by default we create 20 segments, each containing at 
     least 50 markers, if the creation of 20 segments  in each we have 50 markers is impossible we do not create mini-segments).
     After this process is done, we loop over the mini-segments, pick a random marker and go through the mini-segments by picking the nearest      marker after taking a step (default is 0,5 cM) downstream and upstream the mini-segments. 
  

### 3.1 "By hotspots" method

#### 3.1.1 Creation of the segments list

We will now create segments, which will be use to create the submaps later, further explication below, for now use this command :
 
```{r}
s <- createSegmentsListByHotspots(x.me)
```

This function creates a list of chromosomes, in each, you have a list of several segments created thanks to the hotspots file given in argument (files are given with the package), in each segments you have SNPs index.

You can watch a summary of what was done with : 

```{r}
segmentsListSummary(s)
```

This function creates a dataframe with three colums : 

* chromosome
* number_of_segments
* number_of_marker

Now further explanations about why we did that.

This package is mainly used to exploit inbreeding in dense SNPS chip and exome data. 

To do this we use a technique called submapping. 

Let's imagine that our current data is like a map, with all the informations about our individuals and our SNPS, we use this main "map" to create submap, each submap can be considered as a smaller, genome map about our data.

We use this technique because we want to avoid linkage desequilibrium. (See introduction for more information.)

Depending on the method you are using ("By Hotspots" or by "Distance"), we have a submap : a list of markers.
We normally repeat this process aroung a hundred times to make sure that we have no linkage desequilibrium.

Only thing left to do is to compute some probabilities about those submaps (HBD, FLOD score, HFLOD score ...).

#### 3.1.2 Creation of the submaps and computation

After those explanations we will now head toward the creation of submaps using the following commands : 

```{r}
submaps <- makeAllSubmapsByHotspots(x.me, 5, s, verbose=FALSE) #suppressing messages to avoid unnecesary warnings
```

For the sake of clarity we had only created 5 submaps, but generally we do 100.

This function will creates 5 submaps, all the parameters can be modified (use args(makeAllSubmapsByHotspots) for more informations).

The variable submaps becomes an list.submaps object, you can watch the different elements of it with : 
```{r eval=FALSE}
str(submaps) #careful it can become huge depending on your data sizes
```

#### 3.1.3 Descrition of the object submaps
This object contains all the results of the different computation executed during the process of creating n submaps. 
Here is a complete description of each structure in this object : 

* segments_list : the object Segments created previously

```{r eval=FALSE}
str(submaps@segments_list) #careful it can become huge depending on your data sizes
```

* atlas : the list of all the submaps created during the process. Each element of the list is an S4 object. Depending on the method you used the object can be either an snsp.matrix or an hotspots.matrix (here we use the hotspots method). Each submaps contains 14 slots : 
  * submap : the index of each marker picked
  * ncol : the total number of marker picked 
  * nrow : the number of individuals 
  * ped : a dataframe with all the individuals genotype
  * map : a dataframe with all the SNPS informations
  * epsilon : genotyping error rate
  * delta.dist : distance between each marker in cM/bp
  * log.emiss : log of all the emission probabilities of the hidden Markov model 
  * a : a matrix with all the a's estimation
  * f : a matrix with all the f's estimation 
  * likelihood0 : a matrix with all the likehood under the null hypothesis ($f=0$)
  * p.lrt : p value of the likelihood ratio test 
  * HBD.prob : a matrix with all the HBD probabilities computed for each individual
  * FLOD : a matrix with all the FLOD score computed 

```{r eval=FALSE}
str(submaps@atlas)
```

* likelihood_summary : a dataframe with all the likelihood0 and likelihood1 computed over the submaps.

```{r eval=FALSE}
str(submaps@likelihood_summary)
```

* estimation_summary : a dataframe with all the a and f computed over the submaps

```{r eval=FALSE}
str(submaps@estimation_summary)
```

* marker_summary : a dataframe, which gives the number of marker and the number of times it has been picked, 
    * number_of_time_picked
    * number_of_marker


```{r eval=FALSE}
str(submaps@marker_summary)
```

* submaps_summary : a dataframe which gives several informations about the a and f computed over the submaps. The dataframe contains 13 columns: 
  * FID: family identifier
  * IID: individual identifier
  * STATUS: status (1 non-affected, 2 affected, 0 unknown)
  * SUBMAPS: number of submaps used
  * QUALITY: percentage of valid submaps (i.e. submaps with a < 1)
  * F_MIN: minimum f on valid submaps
  * F_MAX: maximum f on valid submaps
  * F_MEAN: mean f on valid submaps
  * F_MEDIAN: median f on valid submaps (recommended to estimate f)
  * A_MEDIAN: median a on valid submaps (recommended to estimate a)
  * pLRT_MEDIAN: median p-value of LRT tests on valid submaps
  * INBRED: a flag indicating if the individual is inbred (pLRT_MEDIAN < 0.05) or not
  * pLRT_<0.05: number of valid submaps with a LRT having a p-value below 0.05

```{r}
submaps@submap_summary
```


* HBD_recap : a dataframe, which contains a mean of all the probabilities HBD for an individual and a given marker.

```{r eval=FALSE}
submaps@HBD_recap[1:10, 1:10] # an individual * marker matrix
```

* FLOD_recap : a dataframe, which contains a mean of all the FLOD score for an individual and a given marker.

```{r eval=FALSE}
submaps@FLOD_recap[1:10, 1:10] # an individual * marker matrix
```


* HBD_segments : a dataframe which contains a list of individuals, and for each indivual a list of segments delimited by at least 5 consecutives markers with a threshold equal to 0.5 (you can modify this value).

```{r eval=FALSE}
str(submaps@HBD_segments[[1]])
```

* HFLOD : a dataframe with the value of HFLOD scores for every markers through all submaps.

```{r eval=FALSE}
str(submaps@HFLOD)
```

* bedmatrix : the bedmatrix object

```{r eval=FALSE}
str(submaps@bedmatrix)
```

* bySegments : a boolean indicating wheater the creation of summary statistics was made by segments 

* unit : the unit of the marker (cM or Bp).

* gap  :  the value of the gap used to pick marker when doing submaps by SNPS. 

### 3.2 "By Hotspot" "by segments" method

We implemented a second inner method of the "By Hotspots" method. The only paramater that changes is 
`recap.by.segments`, it is put to TRUE. In the default "Hotspot" method the HBD probabilities and FLOD scores 
are computed for each marker randomly selected on each segment for the n submaps. With the "Hotspot by segment" 
method HBD probabilities and FLOD scores correspond to the mean of HBD probabilities and FLOD score of each 
marker randomly selected on a segment for the n submaps in such a way that there is only one value for a 
segment. 

#### 3.2.1 Creation of the segments list

We use the same segment list that is used before (s). 

#### 3.2.2 Creation of the submaps and computation

As already said below the only paramater that changes is "recap.by.segments", it is put to TRUE.

```{r}
submaps0 <- makeAllSubmapsByHotspots(x.me, 5, s, verbose=FALSE, recap.by.segments = TRUE)
```

The variable submaps0 becomes an list.submaps obejct, you can watch the different elements of it with : 

```{r eval=FALSE}
str(submaps0) #careful it can become huge depending on your data sizes
```

#### 3.2.3 Description of the object submaps

This object contains all the results of the different computations executed during the process of creating n submaps. 
If you are looking for a complete description of each structure in this object please refer to the  
2.1.3 part. 

### 3.3 "By Distance" method

#### 3.3.1 Creation of the segments list

We will now create segments, which will be use to create the submaps later :
  
```{r}
s1 <- createSegmentsListBySnps(x.me)
```

This function creates a list of chromosomes, in each, you have a list of several segments created thanks to the the gaps between markers, the value of the gap is given in argument, in each segments you have SNPS index. The function creates an object which will contain three slots :
  
* gap           : the value of the gap
* unit          : the unit of the markers ("cM" or "Bp")
* snps.segments : the list of chromosomes 

You can watch a summary of what was done with : 
  
```{r eval=FALSE}
segmentsListSummary(s1@snps.segments)
```

This function creates a dataframe with three colums : 
  
* chromosome
* number_of_segments
* number_of_marker


#### 3.3.2 Creation of the submaps and computation

We will now head toward the creation of submaps using the following commands : 
  
```{r}
submaps1 <- makeAllSubmapsBySnps(x.me, 5, s1, verbose=FALSE)
```

For the sake of clarity we had only created 5 submaps, but generally we do 100.

This function will creates 5 submaps, all the parameters can be modified (use args(makeAllSubmapsBySnps) for more informations).

The variable submaps becomes an list.submaps object, you can watch the different elements of it with : 
```{r eval=FALSE}
str(submaps1) #careful it can become huge depending on your data sizes
```

#### 3.3.3 Descrition of the object submaps
This object contains all the results of the different computations executed during the process of creating n submaps. 
If you are looking for a complete description of each structure in this object please refer to the  
2.1.3 part. 


##4. Parallelism with the package

We implemented a paralellism method to make the creation of the submaps more efficient (we paralellised the creation of the submaps, that is to say, the selection of markers). Make sure to have a Linux environment or one that can support the usage of multiple CPU. 

In order to use it use the `n.cores` argument, the number of CPU that will be use to make the differents submaps in the following functions : 
  
* Fantasio
* makeAllSubmapsByHotspots
* makeAllSubmapsBySnps

```{r eval=FALSE}
submaps6 <- Fantasio(bedmatrix=x.me, segments="Hotspot", n=5, verbose=FALSE, n.cores=10) #for clarity sake we put verbose to FALSE
```

##5. Plotting 

###5.1 HBD plot for a chromosome 
```{r fig1, fig.height = 5, fig.width = 8}
HBD.plot.chr(submaps, chr=20)
```

###5.2 HBD plot for an individual
```{r fig2, fig.height = 5, fig.width = 8}
HBD.plot.id(submaps, individual.id = "HGDP00649", family.id = "HGDP00649")
```

###5.3 HFLOD manhattan plot
```{r fig3, fig.height = 5, fig.width = 10}
HFLOD.manhattan.plot(submaps)
```

The red lines that you see is the value of alpha for the markers.

###5.4 HFLOD for a chromosome
```{r fig4, fig.height = 5, fig.width = 8}
HFLOD.plot.chr(submaps, chr=20)
```

As you can see you have a red line plotted, it gives the moving average of the HFLOD, calculated
on moving windows of 50 markers with the rollmean function of the R package zoo. This
allows checking the consistency of HFLOD calculations (i.e. checking the fact that a high FLOD
score is not due to one submap only). A moving average is computed to remove the impact of a submap with a false positive signal.



